{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:28:54.874003Z",
     "start_time": "2019-10-20T22:28:52.031497Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from  torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "import librosa\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DataSet class for the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:28:54.881981Z",
     "start_time": "2019-10-20T22:28:54.875000Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioData(Dataset):\n",
    "    def __init__(self, path):\n",
    "        #download read data  \n",
    "        sn, sr=librosa.load(path + r'\\data\\train_dirty_male.wav', sr=None)\n",
    "        X = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "        absX = np.abs(X).T.reshape(-1,1,513)\n",
    "        self.x_data =torch.tensor(absX)\n",
    "        \n",
    "\n",
    "        s, sr=librosa.load(path + r'\\data\\train_clean_male.wav', sr=None)\n",
    "        S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        absS = np.abs(S).T.reshape(-1,513)\n",
    "        self.y_data = torch.tensor(absS)\n",
    "\n",
    "        \n",
    "        self.len = self.x_data.shape[0]\n",
    "        \n",
    "        self.clean = librosa.istft(S,hop_length=512)\n",
    "        self.dirty = (X/np.abs(X))  \n",
    "    \n",
    "    \n",
    "        self.snr = 10 * np.log10(np.sum(np.square(s)) / np.sum(np.square(s-sn)))\n",
    "    def __getitem__(self, index):\n",
    "        #return one item on the index\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        #return data length\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading audio train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:28:55.314824Z",
     "start_time": "2019-10-20T22:28:54.882979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original SNR is 6.509321928024292\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Nick\\Documents\\GitHub\\DeepLearningSystems\\Module 2'\n",
    "data = AudioData(path)\n",
    "print(f'The Original SNR is {data.snr}')\n",
    "train_loader = DataLoader(dataset = data, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a four layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:28:55.322802Z",
     "start_time": "2019-10-20T22:28:55.315821Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(CNN, self).__init__()\n",
    "        #no stride 510, non pool 57\n",
    "        self.l1 = nn.Conv1d (1,3,3)\n",
    "        self.l2 = nn.Conv1d (3,9,3)\n",
    "        self.l3 = nn.Linear (1134,700)\n",
    "        self.l4 = nn.Linear (700,513)\n",
    "        \n",
    "        self.p1 = nn.MaxPool1d(3, 2)\n",
    "        self.p2 = nn.MaxPool1d(3, 2)\n",
    "        \n",
    "        self.b1 = nn.BatchNorm1d(3)\n",
    "        self.b2 = nn.BatchNorm1d(9)\n",
    "        self.b3 = nn.BatchNorm1d(700)\n",
    "        \n",
    "        \n",
    "        self.d1 = nn.Dropout(.20)\n",
    "        self.d2 = nn.Dropout(.10)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out1 = self.d1(self.b1(self.p1(F.relu(self.l1(x)))))\n",
    "        out2 = self.b2(self.p2(F.relu(self.l2(out1))))\n",
    "        out2 = self.d2(out2.view(-1, out2.shape[1]*out2.shape[2]))\n",
    "        out3 = self.b3(F.relu(self.l3(out2)))\n",
    "        out3 = F.relu(self.l4(out3))\n",
    "        return out1, out2, out3\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:28:55.331779Z",
     "start_time": "2019-10-20T22:28:55.323800Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    tst3 = nn.Conv1d (1,3,3)\n",
    "    tst4 = nn.MaxPool1d(3, 2)\n",
    "    tst5 = nn.Conv1d (3,9,3)\n",
    "    tst6 = nn.MaxPool1d(3,2)\n",
    "    dat = data.x_data\n",
    "    meme = tst6(tst5(tst4(tst3(dat))))\n",
    "    print(meme.shape[1] * meme.shape[2])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the optimizor to Adam and the Loss to MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:28:55.346738Z",
     "start_time": "2019-10-20T22:28:55.332776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of CNN(\n",
      "  (l1): Conv1d(1, 3, kernel_size=(3,), stride=(1,))\n",
      "  (l2): Conv1d(3, 9, kernel_size=(3,), stride=(1,))\n",
      "  (l3): Linear(in_features=1134, out_features=700, bias=True)\n",
      "  (l4): Linear(in_features=700, out_features=513, bias=True)\n",
      "  (p1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (p2): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (b1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b2): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b3): BatchNorm1d(700, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d1): Dropout(p=0.2, inplace=False)\n",
      "  (d2): Dropout(p=0.1, inplace=False)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "net2 = CNN()\n",
    "print(net2.parameters)\n",
    "optA = optim.Adam(net2.parameters(), lr = 0.001)\n",
    "critA = nn.MSELoss()\n",
    "epochs = 501\n",
    "printA = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T05:02:21.106111Z",
     "start_time": "2019-10-20T05:02:21.101125Z"
    }
   },
   "source": [
    "## Training over 500 epochs and printing every 50 itterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:18.945451Z",
     "start_time": "2019-10-20T22:28:55.347736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Loss = 0.09612 on Epoch 0 and the SNR is 3.63\n",
      "The Loss = 0.01224 on Epoch 50 and the SNR is 10.09\n",
      "The Loss = 0.01016 on Epoch 100 and the SNR is 10.93\n",
      "The Loss = 0.00838 on Epoch 150 and the SNR is 11.48\n",
      "The Loss = 0.00710 on Epoch 200 and the SNR is 11.86\n",
      "The Loss = 0.00669 on Epoch 250 and the SNR is 11.91\n",
      "The Loss = 0.00643 on Epoch 300 and the SNR is 11.81\n",
      "The Loss = 0.00613 on Epoch 350 and the SNR is 11.25\n",
      "The Loss = 0.00529 on Epoch 400 and the SNR is 10.92\n",
      "The Loss = 0.00550 on Epoch 450 and the SNR is 11.23\n",
      "The Loss = 0.00473 on Epoch 500 and the SNR is 11.07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    lossL = []\n",
    "    for i,dat in enumerate(train_loader):\n",
    "        inputs, labels = dat\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optA.zero_grad()\n",
    "        out1,out2,net_out = net2(inputs)\n",
    "        loss = critA(net_out, labels)\n",
    "        lossL.append(loss.item())\n",
    "        loss.backward()\n",
    "        optA.step()\n",
    "    if (epoch%printA) == 0:\n",
    "        ntst = data.dirty\n",
    "        lib = data.clean\n",
    "        out1,out2,net_out = net2(data.x_data)\n",
    "        ntst2= np.multiply(ntst, net_out.detach().numpy().T)\n",
    "        ntest3 = librosa.istft(ntst2,hop_length=512)\n",
    "        SNR = 10 * np.log10(np.sum(np.square(lib)) / np.sum(np.square(lib-ntest3)))\n",
    "        print(f'The Loss = {np.mean(lossL):0.5f} on Epoch {epoch} and the SNR is {SNR:0.2f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T17:27:35.783177Z",
     "start_time": "2019-10-19T17:27:35.781180Z"
    }
   },
   "source": [
    "## Testintg Model On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:19.008283Z",
     "start_time": "2019-10-20T22:35:18.946449Z"
    }
   },
   "outputs": [],
   "source": [
    "st, sr=librosa.load(path + r'\\data\\test_x_01.wav', sr=None)\n",
    "Xt=librosa.stft(st, n_fft=1024, hop_length=512)\n",
    "absXt =np.abs(Xt).T.reshape(-1,1,513)\n",
    "absXt.shape\n",
    "tdata = Variable(torch.tensor(absXt))\n",
    "out1, out2, net_out = net2(tdata)\n",
    "tst = (Xt/np.abs(Xt))\n",
    "tst2= np.multiply(tst, net_out.detach().numpy().reshape(142,513).T)\n",
    "sh_test = librosa.istft(tst2,hop_length=512)\n",
    "librosa.output.write_wav(path + r'\\data\\test_s_01_recons.wav', sh_test, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:19.091062Z",
     "start_time": "2019-10-20T22:35:19.009281Z"
    }
   },
   "outputs": [],
   "source": [
    "st, sr=librosa.load(path + r'\\data\\test_x_02.wav', sr=None)\n",
    "Xt=librosa.stft(st, n_fft=1024, hop_length=512)\n",
    "absXt =np.abs(Xt).T.reshape(-1,1,513)\n",
    "absXt.shape\n",
    "tdata = Variable(torch.tensor(absXt))\n",
    "out1, out2, net_out = net2(tdata)\n",
    "tst = (Xt/np.abs(Xt))\n",
    "tst2= np.multiply(tst, net_out.detach().numpy().reshape(380,513).T)\n",
    "sh_test = librosa.istft(tst2,hop_length=512)\n",
    "librosa.output.write_wav(path + r'\\data\\test_s_02_recons.wav', sh_test, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T06:24:55.237987Z",
     "start_time": "2019-10-20T06:24:55.229510Z"
    }
   },
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:19.099041Z",
     "start_time": "2019-10-20T22:35:19.092059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from  torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "import librosa\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data & Converting to 2440,1,20,513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:20.855110Z",
     "start_time": "2019-10-20T22:35:19.100038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2440, 1, 20, 513])\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Nick\\Documents\\GitHub\\DeepLearningSystems\\Module 2'\n",
    "sn, sr=librosa.load(path + r'\\data\\train_dirty_male.wav', sr=None)\n",
    "X = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "dirty = (X/np.abs(X))\n",
    "absX = np.abs(X).T\n",
    "x_data =torch.tensor(absX)\n",
    "\n",
    "\n",
    "newx = np.empty((2440,20,513))  \n",
    "for i in range(2440):\n",
    "    newx[i] = x_data[i:20+i]\n",
    "newx = torch.tensor(newx.reshape((-1,1,20,513))).to(torch.device(\"cuda:0\"))\n",
    "print(newx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:21.007595Z",
     "start_time": "2019-10-20T22:35:20.856107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2440, 513])\n"
     ]
    }
   ],
   "source": [
    "s, sr=librosa.load(path + r'\\data\\train_clean_male.wav', sr=None)\n",
    "S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "clean = librosa.istft(S,hop_length=512)\n",
    "absS = np.abs(S).T\n",
    "y_data = torch.tensor(absS)\n",
    "newy = np.empty((2440,513))  \n",
    "for i in range(19,2459):\n",
    "    newy[i-19] = y_data[i]\n",
    "newy = torch.tensor(newy).to(torch.device(\"cuda:0\"))\n",
    "print(newy.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:21.011584Z",
     "start_time": "2019-10-20T22:35:21.008592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The new x shape is torch.Size([2440, 1, 20, 513]) and the new y shape is torch.Size([2440, 513])\n"
     ]
    }
   ],
   "source": [
    "print(f' The new x shape is {newx.shape} and the new y shape is {newy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:21.019562Z",
     "start_time": "2019-10-20T22:35:21.012582Z"
    }
   },
   "outputs": [],
   "source": [
    "#BatchNormAfterActivation\n",
    "class CNN2(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.l1 = nn.Conv2d (1,3,1)\n",
    "        self.l2 = nn.Conv2d (3,6,3)\n",
    "        \n",
    "        self.l3 = nn.Linear (1008,1000)\n",
    "        self.l4 = nn.Linear (1000,513)\n",
    "    \n",
    "        self.p1 = nn.MaxPool2d(3, 2)\n",
    "        self.p2 = nn.MaxPool2d(3, 3)\n",
    "        \n",
    "        self.b1 = nn.BatchNorm2d(3)\n",
    "        self.b2 = nn.BatchNorm2d(6)\n",
    "        self.b3 = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        \n",
    "        self.d1 = nn.Dropout2d(.20)\n",
    "        self.d2 = nn.Dropout2d(.10)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out1 = self.d1(self.b1(self.p1(F.relu(self.l1(x)))))\n",
    "        \n",
    "        out2 = self.d2(self.b2(self.p2(F.relu(self.l2(out1)))))\n",
    "        out2 = out2.view(-1, out2.shape[1]*out2.shape[2] *  out2.shape[3])\n",
    "\n",
    "        out3 = self.b3(F.relu(self.l3(out2)))\n",
    "        out4 = F.relu(self.l4(out3))\n",
    "        return out1, out2, out4\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:21.025547Z",
     "start_time": "2019-10-20T22:35:21.020560Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    tst3 = nn.Conv2d (1,3,1).double().cuda()\n",
    "    tst4 = nn.MaxPool2d(3, 2)\n",
    "    tst5 = nn.Conv2d (3,6,3).double().cuda()\n",
    "    tst6 = nn.MaxPool2d(3,3)\n",
    "    meme = tst6(tst5(tst4(tst3(newx))))\n",
    "    print(meme.shape[1] * meme.shape[2] * meme.shape[3] ) \n",
    "    del meme, tst3, tst4, tst5, tst6\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Model Optimizor, Loss , & Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:35:21.050480Z",
     "start_time": "2019-10-20T22:35:21.026544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of CNN2(\n",
      "  (l1): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (l2): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (l3): Linear(in_features=1008, out_features=1000, bias=True)\n",
      "  (l4): Linear(in_features=1000, out_features=513, bias=True)\n",
      "  (p1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (p2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (b1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d1): Dropout2d(p=0.2, inplace=False)\n",
      "  (d2): Dropout2d(p=0.1, inplace=False)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "net3 = CNN2().double()\n",
    "net3.to(torch.device(\"cuda:0\"))\n",
    "print(net3.parameters)\n",
    "optA3 = optim.Adam(net3.parameters(), lr = 0.001)\n",
    "critA3 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Conv2D Model Printing Loss & SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:46:14.067697Z",
     "start_time": "2019-10-20T22:35:21.051478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Loss = 0.23861 at Epoch 0 and the SNR is -2.64\n",
      "The Loss = 0.04644 at Epoch 100 and the SNR is 3.84\n",
      "The Loss = 0.02051 at Epoch 200 and the SNR is 7.49\n",
      "The Loss = 0.01294 at Epoch 300 and the SNR is 9.35\n",
      "The Loss = 0.01005 at Epoch 400 and the SNR is 10.33\n",
      "The Loss = 0.00933 at Epoch 500 and the SNR is 10.64\n",
      "The Loss = 0.00789 at Epoch 600 and the SNR is 11.24\n",
      "The Loss = 0.00743 at Epoch 700 and the SNR is 11.52\n",
      "The Loss = 0.00647 at Epoch 800 and the SNR is 12.02\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "srt = sr\n",
    "totEpoch = 801\n",
    "tt = (np.random.rand(19*513)/100).reshape((19,513))\n",
    "for epoch in range(totEpoch):\n",
    "    #inputs, labels = torch.tensor(newx.reshape((-1,1,20,513))), torch.tensor(newy)\n",
    "    inputs, labels = Variable(newx), Variable(newy)\n",
    "    optA3.zero_grad()\n",
    "    out1,out2,net_out = net3(inputs)\n",
    "    loss = critA3(net_out, labels)\n",
    "    loss.backward()\n",
    "    optA3.step()\n",
    "    if epoch%100 == 0:\n",
    "        huh = np.append(tt,net_out.detach().cpu().numpy()).reshape(2459,513)\n",
    "        ntst2= np.multiply(dirty, huh.T)\n",
    "        ntest3 = librosa.istft(ntst2,hop_length=512)\n",
    "        SNR = 10 * np.log10(np.sum(np.square(clean)) / np.sum(np.square(clean-ntest3)))\n",
    "        print(f'The Loss = {loss:0.5f} at Epoch {epoch} and the SNR is {SNR:0.2f}')\n",
    "        if epoch==totEpoch -1:\n",
    "            librosa.output.write_wav(path + r'\\data\\male_clean(2d)).wav', ntest3 , srt)\n",
    "        del huh, ntst2, ntest3, SNR\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "del inputs, labels, net_out\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:46:14.109585Z",
     "start_time": "2019-10-20T22:46:14.068694Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = r'\\test_x_01'\n",
    "sn, sr=librosa.load(path + r'\\data' + fname + '.wav', sr=None)\n",
    "Xt = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "\n",
    "\n",
    "absXt = np.abs(Xt).T\n",
    "xt_data =torch.tensor(absXt)\n",
    "newxt = np.empty((123,20,513))  \n",
    "for i in range(123):\n",
    "    newxt[i] = xt_data[i:20+i]\n",
    "newxt = torch.tensor(newxt.reshape((-1,1,20,513))).to(torch.device(\"cuda:0\"))\n",
    "out1, out2, net_out2 = net3(newxt)\n",
    "\n",
    "dirtyt = (Xt/np.abs(Xt))\n",
    "tt = (np.random.rand(19*513)/100).reshape((19,513))\n",
    "\n",
    "huh2 = np.append(tt,net_out2.detach().cpu().numpy()).reshape(142,513)\n",
    "tst2t = np.multiply(dirtyt,huh2.T)\n",
    "sh_testt = librosa.istft(tst2t,hop_length=512)\n",
    "librosa.output.write_wav(path + r'\\data' + fname + '_recons(2d).wav', sh_testt, sr)\n",
    "del sn, sr, Xt, absXt, xt_data, newxt, out1, out2, net_out2, dirtyt, tt, huh2, tst2t, sh_testt\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T22:46:14.195355Z",
     "start_time": "2019-10-20T22:46:14.110582Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = r'\\test_x_02'\n",
    "sn, sr=librosa.load(path + r'\\data' + fname + '.wav', sr=None)\n",
    "Xt = librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "absXt = np.abs(Xt).T\n",
    "xt_data =torch.tensor(absXt)\n",
    "newxt = np.empty((361,20,513))  \n",
    "for i in range(361):\n",
    "    newxt[i] = xt_data[i:20+i]\n",
    "newxt = torch.tensor(newxt.reshape((-1,1,20,513))).to(torch.device(\"cuda:0\"))\n",
    "out1, out2, net_out2 = net3(newxt)\n",
    "\n",
    "dirtyt = (Xt/np.abs(Xt))\n",
    "tt = (np.random.rand(19*513)/100).reshape((19,513))\n",
    "\n",
    "huh2 = np.append(tt,net_out2.detach().cpu().numpy()).reshape(380,513)\n",
    "tst2t = np.multiply(dirtyt,huh2.T)\n",
    "sh_testt = librosa.istft(tst2t,hop_length=512)\n",
    "librosa.output.write_wav(path + r'\\data' + fname + '_recons(2d).wav', sh_testt, sr)\n",
    "\n",
    "del sn, sr, Xt, absXt, xt_data, newxt, out1, out2, net_out2, dirtyt, tt, huh2, tst2t, sh_testt\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
